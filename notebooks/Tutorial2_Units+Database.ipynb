{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "contrary-corner",
   "metadata": {},
   "source": [
    "#### AMPEL intro\n",
    "\n",
    "AMPEL is software framework designed for processing heterogeneous streamed data. \n",
    "\n",
    "AMPEL was not developed to provide a specific scientific resource, but rather an environment where it is easy to ensure that a scientific program fulfills the strict requirement of the next generation real-time experiments: efficient and powerful analysis, where provenance and reproducibiltiy is paramount. In particular, to guarantee the last point requires algorithms (which make real-time deicsions) be separated from infrastructure (which will likely evolve with time and project phase).\n",
    "\n",
    "An AMPEL _user_ constructs a configuration file which describes every step of how an incoming alert stream should be processed. This can be broken down into selecting which _units_ should be executed, and which _parameters_ each of these should be provided. An AMPEL _live instance_ executes these units, based on the input data, as requested and stores all intermediate and final data in a databse. \n",
    "\n",
    "Provenance/reproducibility is ensured through multiple layers. First, each live instance is run from a container which can be retrieved later and together with a data archive replay the full stream. Second, AMPEL contains an extensive set of logs and a transient-specific _Journal_ which details all related actions/decisions. Finally, each unit and channel configuration file is drawn from a specific (tagged) github version. \n",
    "\n",
    "The series of notebooks provided here gradually builds toward a sample full configration. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-adjustment",
   "metadata": {},
   "source": [
    "#### Sample science case\n",
    "\n",
    "Each AMPEl _channel_ is designed with a science goal (or \"hypothesis/test\") in mind. A much discussed current topic is the origin of the extragalactic neutrino flux observed e.g. by IceCube, with one of the potential sources being supernovae interacting with circumstellar material (SNIIn). We here wish to investigate whether a particular subtype of these, SN2009ip-like SNe with recent previous outbursts, are regularly found within the uncertainty region of neutrino alerts. \n",
    "\n",
    "The steps for this science program would be: Identify transients with optical lightcurves compatible with SN2009ip AND which coincide with neutrino alerts. For such targets, obtain follow-up spectroscopy to confirm classification (i.e. an external reaction). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-hacker",
   "metadata": {},
   "source": [
    "#### This notebook - Tutorial 2\n",
    "\n",
    "This notebook will repeat the analysis presented in the first tutorial, but where all units are read from tagged (github) repositories. They can from there be referenced, be included in a computer center AMPEL instance and be distributed to the community.\n",
    "\n",
    "These can be found in the `ampel/contrib/sample/` subdirectories of the `Ampel-contrib-sample` repository.\n",
    "\n",
    "Furthermore, intermediate results will her be stored in a local MongoDB database and the AMPEL schedulers will be used to carry out the requested operations. This notebook thus assumes a mongod instance to be running and accessible through 27017. (The port can be changed through the `mongo` key of the `ampel_config.yml` file).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%load_ext ampel_quick_import\n",
    "%qi DevAmpelContext AmpelLogger T2Processor T3Processor ChannelModel AlertProcessor TarAlertLoader ChannelModel AbsAlertFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMPEL_CONF = \"../../ampel_config.yml\"\n",
    "ALERT_ARCHIVE = '../sample_data/ztfpub_200917_pruned.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The operation context is created based on a setup configuration file.\n",
    "# db_prefix sets the DB name to use\n",
    "ctx = DevAmpelContext.load(\n",
    "    config_file_path = AMPEL_CONF,\n",
    "    db_prefix = \"AmpelTutorial\",\n",
    "    purge_db = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A scientific program, a channel, is added\n",
    "ctx.add_channel(\n",
    "    name=\"demo_SN09if\",\n",
    "    access=['ZTF', 'ZTF_PUB']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The channel is constructed from two units, each controlled by parameters. \n",
    "# Lets start with the straightforward filter \n",
    "filter_conf = {\n",
    "    'min_rb':0.3,\n",
    "    'min_ndet':7,\n",
    "    'min_tspan':10,\n",
    "    'max_tspan' : 200,\n",
    "    'min_gal_lat':15,\n",
    "}\n",
    "filter_config_id = ctx.add_config_id( filter_conf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The template matching has now been moved into a separate unit:\n",
    "# T2SNcosmoComp\n",
    "# where we added some configurability. \n",
    "match_conf = {\n",
    "    'target_model_name':'v19-2009ip-corr', \n",
    "    'base_model_name':'salt2', \n",
    "    'chi2dof_cut':2.,\n",
    "    'chicomp_scaling':0.5,\n",
    "}\n",
    "match_config_id = ctx.add_config_id( match_conf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A channel can specify which streams to read, how these should be combined and what units\n",
    "# should be run on each data combination.\n",
    "# This is provided as directives to the AlertProcessor, which besides processing the alerts\n",
    "# also submit tickets to the DB concerning further operations to execute for any transients\n",
    "# that pass the initial filter stage.\n",
    "ap = AlertProcessor(\n",
    "    context = ctx,\n",
    "    process_name = \"ipyton_notebook_test\",\n",
    "    supplier = \"ZiAlertSupplier\",\n",
    "    log_profile = \"debug\",\n",
    "    directives = [\n",
    "        {\n",
    "            \"channel\": \"demo_SN09if\", \n",
    "            \"filter\": {\"unit\": \"SimpleDecentFilterCopy\",\"config\": filter_config_id\n",
    "                        },\n",
    "            \"stock_update\": \"ZiStockIngester\",\n",
    "            't0_add': {\n",
    "                \"ingester\": \"ZiAlertContentIngester\",\n",
    "                \"t1_combine\": [\n",
    "                    {\n",
    "                        \"ingester\": \"PhotoCompoundIngester\",\n",
    "                        \"config\": {\"combiner\": \"ZiT1Combiner\"},\n",
    "                        \"t2_compute\": {\n",
    "                            \"ingester\": \"PhotoT2Ingester\",\n",
    "                            \"config\": {\"tags\": [\"ZTF\"]},\n",
    "                            \"units\": [\n",
    "                                {'unit': 'T2SNcosmoComp',\n",
    "                                 'config': match_config_id\n",
    "                                },\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide a link to the alert collection to use\n",
    "ap.set_loader(TarAlertLoader(file_path=ALERT_ARCHIVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap.set_iter_max(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2p = T2Processor(context=ctx, process_name=\"T2Processor_test\", log_profile=\"debug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2p.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-partition",
   "metadata": {},
   "source": [
    "So far an input data stream has been filtered, and some sort of calculation has been done on the accepted sample. The next step for a full channel is usually some sort of _reaction_. These can vary between sending immediate alarms (e.g. through Slack or GCN), triggering follow-up observations or propagating information (e.g. for inspection in a frontent such as SkyPortal). \n",
    "\n",
    "Such reactions take place in the T3 tier. A simple `T3HelloWorld` unit is used, but the  `react` method can be configured to do most other things. Sample T3 units react with TNS, Slack, Dropbox, SkyPortal and GCN.\n",
    "\n",
    "Key steps of configuring the T3 procss comes through the `selection` directive, where we select tansients that produced the required target match, and the `execute` directive which regulates which T3 units are run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test base\n",
    "t3 = T3Processor(\n",
    "    context=ctx,\n",
    "    process_name = \"T3Processor_test\",\n",
    "    log_profile = \"default\", # debug\n",
    "    channel = \"demo_SN09if\",\n",
    "    directives = [ {\n",
    "        \"select\": {\n",
    "            \"unit\": \"T3FilteringStockSelector\",\n",
    "            \"config\": {\n",
    "                't2_filter':  {\n",
    "                    'unit': 'T2SNcosmoComp',\n",
    "                    'match': {'target_match': True}\n",
    "                }, \n",
    "            }\n",
    "        },\n",
    "        \"load\": {\n",
    "            \"unit\": \"T3SimpleDataLoader\",\n",
    "            \"config\": {\n",
    "                \"directives\": [\"TRANSIENT\", \"DATAPOINT\", \"COMPOUND\", \"T2RECORD\"],\n",
    "            }\n",
    "\n",
    "        },\n",
    "        \"run\": {\n",
    "            \"unit\": \"T3UnitRunner\",\n",
    "            \"config\": {\n",
    "                \"directives\": [\n",
    "                      {\n",
    "                            \"project\": {\n",
    "                                \"unit\": \"T3ChannelProjector\",\n",
    "                                \"config\": {\n",
    "                                    \"channel\": \"demo_SN09if\"\n",
    "                                }\n",
    "                            },\n",
    "                            \"execute\": [\n",
    "                                {\n",
    "                                    \"unit\": \"T3HelloWorld\",\n",
    "                                    \"config\": {\n",
    "                                        't2info_from' : ['T2SNcosmoComp']\n",
    "                                    },\n",
    "                                },\n",
    "                            ]\n",
    "\n",
    "                      }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    } ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "t3.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
