{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "floating-chorus",
   "metadata": {},
   "source": [
    "#### AMPEL intro\n",
    "\n",
    "AMPEL is software framework designed for processing heterogeneous streamed data. \n",
    "\n",
    "AMPEL was not developed to provide a specific scientific resource, but rather an environment where it is easy to ensure that a scientific program fulfills the strict requirement of the next generation real-time experiments: efficient and powerful analysis, where provenance and reproducibiltiy is paramount. In particular, to guarantee the last point requires algorithms (which make real-time deicsions) be separated from infrastructure (which will likely evolve with time and project phase).\n",
    "\n",
    "An AMPEL _user_ constructs a configuration file which describes every step of how an incoming alert stream should be processed. This can be broken down into selecting which _units_ should be executed, and which _parameters_ each of these should be provided. An AMPEL _live instance_ executes these units, based on the input data, as requested and stores all intermediate and final data in a databse. \n",
    "\n",
    "Provenance/reproducibility is ensured through multiple layers. First, each live instance is run from a container which can be retrieved later and together with a data archive replay the full stream. Second, AMPEL contains an extensive set of logs and a transient-specific _Journal_ which details all related actions/decisions. Finally, each unit and channel configuration file is drawn from a specific (tagged) github version. \n",
    "\n",
    "The series of notebooks provided here gradually builds toward a sample full configration. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-sellers",
   "metadata": {},
   "source": [
    "#### Sample science case\n",
    "\n",
    "Each AMPEl _channel_ is designed with a science goal (or \"hypothesis/test\") in mind. A much discussed current topic is the origin of the extragalactic neutrino flux observed e.g. by IceCube, with one of the potential sources being supernovae interacting with circumstellar material (SNIIn). We here wish to investigate whether a particular subtype of these, SN2009ip-like SNe with recent previous outbursts, are regularly found within the uncertainty region of neutrino alerts. \n",
    "\n",
    "The steps for this science program would be: Identify transients with optical lightcurves compatible with SN2009ip AND which coincide with neutrino alerts. For such targets, obtain follow-up spectroscopy to confirm classification (i.e. an external reaction). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-crossing",
   "metadata": {},
   "source": [
    "#### This notebook\n",
    "\n",
    "This notebook reads alerts from a provided fixed collection of alerts, filters these and performs a lightcurve template match. In particular, it compares whether the lightcurve is better fit by SN2009ip than a normal SNIa (the main assumed false-positive).\n",
    "\n",
    "This is done fully sequential, in the notebook, without relying on any external database or units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext ampel_quick_import\n",
    "%qi AmpelLogger SimpleDecentFilterCopy DevAlertProcessor AbsLightCurveT2Unit LightCurve ZTFAlert\n",
    "from ampel.type import T2UnitResult\n",
    "import numpy as np\n",
    "from astropy.table import Table\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(action=\"ignore\", category=DeprecationWarning, module=\"sncosmo\")\n",
    "    import sncosmo    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-mouse",
   "metadata": {},
   "source": [
    "### Traversing and filtering a local alert collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to an alert archive.\n",
    "# In principle, the full ZTF alert history can be accessed through https://ztf.uw.edu/alerts/public/\n",
    "# TODO: hopefully put a subsection of this inside the docker\n",
    "ALERT_ARCHIVE = '/home/jnordin/github/ampelv07/Ampel-notebooks/ztf/skyportal/HU_TNS_PARTNER.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every log message is (later) stored in the DB\n",
    "logger = AmpelLogger.get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the first step, a basic filter will be applied to the alert stream\n",
    "# In particular, the search we will do is only meaningful for transients with a certain number\n",
    "# of detections.\n",
    "t0filter = SimpleDecentFilterCopy(\n",
    "        min_rb=0.3,\n",
    "        min_ndet=7,\n",
    "        min_tspan=10,\n",
    "        max_tspan = 200,\n",
    "        min_gal_lat=15,\n",
    "        logger=logger\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sets up a local alert processor, which can traverse a collection of ZTF alerts.\n",
    "# AMPEL contains other alert processors, most notable those which accepts a live stream (e.g. Kafka)\n",
    "ap = DevAlertProcessor( t0filter )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets now process the first iter_max alerts\n",
    "iter_max = 100\n",
    "n_processed = ap.process_tar( ALERT_ARCHIVE, iter_max=iter_max )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-average",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Processed %s alerts out of which %s were accepted'%(n_processed,len(ap.get_accepted_alerts())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-microwave",
   "metadata": {},
   "source": [
    "### Comparing the lightcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we define the calculation we wish to apply to the alert content (a photometric LightCurve)\n",
    "class T2FindSN2009ip(AbsLightCurveT2Unit):\n",
    "    \"\"\"\n",
    "    This module tests whether a state LightCurve is well matched by SN2009ip.\n",
    "    To be this, it has to:\n",
    "    - Provide good fit to the data\n",
    "    - Provide a better fit than a SNIa lightcurve\n",
    "    Evaluations done using SNCosmo.\n",
    "    Warning: MW or host galaxy reddening not accounted for!\n",
    "    \n",
    "    The run method, applied to a LightCurve, will return a dict (T2UnitResult).\n",
    "    In this \n",
    "       'model_match':True\n",
    "    for selected objects. \n",
    "    (For this sample case we also include the fitted model).\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    saltmodel = sncosmo.Model(source='salt2')\n",
    "    sn09ipmodel = sncosmo.Model(source='v19-2009ip-corr')\n",
    "    \n",
    "        \n",
    "    def run(self, light_curve: LightCurve) -> T2UnitResult:\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        light_curve: \"ampel.view.LightCurve\" instance.\n",
    "        See the LightCurve docstring for more info.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "        \"\"\"\n",
    "\n",
    "        self.logger.info('Fitting %s'%(light_curve.stock_id) )\n",
    "\n",
    "        # Create SNCosmo input table\n",
    "        phot = np.asarray( light_curve.get_ntuples(('jd','magpsf','sigmapsf','fid')) )\n",
    "        phot_tab = Table(phot,names=('jd','magpsf','sigmapsf','fid'))\n",
    "        phot_tab['band'] = 'ztfband'\n",
    "        for fid, fname in zip( [1,2,3], ['ztfg','ztfr','ztfi']):\n",
    "            phot_tab['band'][phot_tab['fid']==fid] = fname\n",
    "        phot_tab['flux'] = 10 ** (-(phot_tab['magpsf'] - 25) / 2.5)\n",
    "        phot_tab['fluxerr'] = np.abs(phot_tab['flux'] * (-phot_tab['sigmapsf'] / 2.5 * np.log(10)))\n",
    "        phot_tab['zp'] = 25\n",
    "        phot_tab['zpsys'] = 'ab'\n",
    "        \n",
    "        # Fit SNIa\n",
    "        result, fitted_model = sncosmo.fit_lc(\n",
    "            phot_tab, self.saltmodel,\n",
    "            ['z', 't0', 'x0', 'x1', 'c'],  # parameters of model to vary\n",
    "            bounds={'z':(0., 0.2),'x1':(-5,5),'c':(-1,3)})  \n",
    "        chidof_snia = result.chisq / result.ndof\n",
    "        \n",
    "        # Fit Vincenzi et al. 2019 model of SN2009ip\n",
    "        # SN2009ip-like objects as neutrino sources?\n",
    "        result, fitted_model = sncosmo.fit_lc(\n",
    "            phot_tab, self.sn09ipmodel, vparam_names=['z', 't0', 'amplitude'], bounds={'z':(0,0.2)}  )  \n",
    "        chidof_09ip = result.chisq / result.ndof\n",
    "        \n",
    "        # Gather information to propagate / log\n",
    "        fit_info = {'chidof_snia':chidof_snia,'chidof_09ip':chidof_09ip}\n",
    "\n",
    "        # Crude decision made\n",
    "        if chidof_09ip>3:\n",
    "            fit_info['model_match'] = False\n",
    "            fit_info['info'] = 'Poor lc match'\n",
    "        elif chidof_snia<chidof_09ip:\n",
    "            fit_info['model_match'] = False\n",
    "            fit_info['info'] = 'Better SNIa fit'\n",
    "\n",
    "        else:\n",
    "            fit_info['model_match'] = True\n",
    "            fit_info['info'] = 'Good match'\n",
    "            fit_info['fit_table'] = phot_tab\n",
    "            fit_info['fit_model'] = fitted_model\n",
    "            fit_info['fit_errors'] = result.errors\n",
    "        \n",
    "        self.logger.info(\"\",extra={'SN90ip_match':fit_info['model_match']} )\n",
    "\n",
    "        \n",
    "        return fit_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-theory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate our lightcurve tester\n",
    "t2 = T2FindSN2009ip(logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traverse the accepted alerts and record output\n",
    "t2_output = {}\n",
    "for k, al in enumerate(ap.get_accepted_alerts()):\n",
    "    lc = ZTFAlert.to_lightcurve(pal=al)\n",
    "    t2_output[al.id] = t2.run(lc)\n",
    "    # No time for this\n",
    "    if k==100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sn, t2dict in t2_output.items():\n",
    "    print(sn)\n",
    "    if not t2dict['model_match']: \n",
    "        continue\n",
    "    _ = sncosmo.plot_lc(t2dict['fit_table'], model=t2dict['fit_model'], errors=t2dict['fit_errors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-sponsorship",
   "metadata": {},
   "source": [
    "We now have the initial seed for a scientific program. There are obvious _scientific_ improvements that can be made: take reddening into account, more sophisticated model treatment or why not add some sklearn ML test? Most of these can be constructed as straightforward extensions of `T2FindSN2009ip`. \n",
    "\n",
    "However, if the goal is to construct a real-time experiment for the Very Rubin Observatory there are also a series of _infrastructure_ questions to answer: How does one apply the test to the full LSST alert stream? How do we guarantee provenance (that we can recover what happened at what time) for the full study? How can the scientific experiment be referenced in a way that it can be recreated in 10 years? \n",
    "\n",
    "AMPEL contains tools that can take care of such infrastructure questions, with the goal that scientists can focus on finding, for example, the counterparts to extragalactic neutrinos. The next notebook will describe how the test outlined above can be integrated in a full AMPEL instance. At a computer center this can then be applied either to large archive datasets or to a live alert stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampel.contrib.sample.t2.T2SNcosmoComp import T2SNcosmoComp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = T2SNcosmoComp(target_model_name='v19-2009ip-corr', base_model_name='salt2', chi2dof_cut=2, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traverse the accepted alerts and record output\n",
    "t2_output = {}\n",
    "for k, al in enumerate(ap.get_accepted_alerts()):\n",
    "    lc = ZTFAlert.to_lightcurve(pal=al)\n",
    "    t2_output[al.id] = t2.run(lc)\n",
    "    # No time for this\n",
    "    if k==100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c7efea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
