{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "overhead-hacker",
   "metadata": {},
   "source": [
    "#### AMPEL intro\n",
    "\n",
    "AMPEL is software framework designed for processing heterogeneous streamed data. \n",
    "\n",
    "AMPEL was not developed to provide a specific scientific resource, but rather an environment where it is easy to ensure that a scientific program fulfills the strict requirement of the next generation real-time experiments: efficient and powerful analysis, where provenance and reproducibiltiy is paramount. In particular, to guarantee the last point requires algorithms (which make real-time deicsions) be separated from infrastructure (which will likely evolve with time and project phase).\n",
    "\n",
    "An AMPEL _user_ constructs a configuration file which describes every step of how an incoming alert stream should be processed. This can be broken down into selecting which _units_ should be executed, and which _parameters_ each of these should be provided. An AMPEL _live instance_ executes these units, based on the input data, as requested and stores all intermediate and final data in a databse. \n",
    "\n",
    "Provenance/reproducibility is ensured through multiple layers. First, each live instance is run from a container which can be retrieved later and together with a data archive replay the full stream. Second, AMPEL contains an extensive set of logs and a transient-specific _Journal_ which details all related actions/decisions. Finally, each unit and channel configuration file is drawn from a specific (tagged) github version. \n",
    "\n",
    "The series of notebooks provided here gradually builds toward a sample full configration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-conference",
   "metadata": {},
   "source": [
    "#### Sample science case\n",
    "\n",
    "Each AMPEl _channel_ is designed with a science goal (or \"hypothesis/test\") in mind. A much discussed current topic is the origin of the extragalactic neutrino flux observed e.g. by IceCube, with one of the potential sources being supernovae interacting with circumstellar material (SNIIn). We here wish to investigate whether a particular subtype of these, SN2009ip-like SNe with recent previous outbursts, are regularly found within the uncertainty region of neutrino alerts. \n",
    "\n",
    "The steps for this science program would be: Identify transients with optical lightcurves compatible with SN2009ip AND which coincide with neutrino alerts. For such targets, obtain follow-up spectroscopy to confirm classification (i.e. an external reaction). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-prayer",
   "metadata": {},
   "source": [
    "#### This notebook - Tutorial 4\n",
    "\n",
    "This notebook reproduces the results of Tutorial 3, but through processing the `SampleChannel` configuration found at\n",
    "\n",
    "`Ampel-contrib-sample/conf/ampel-contrib-sample/channel/SAMPLE_CHANNEL.yml` \n",
    "\n",
    "At this stage the channel is ready to be included in a live AMPEL instance. This can either be used to process a large set of archive data, or for processing a real-time data stream. Simultaneously, the channel configuration and the unit algorithms serves to provide a full, referencable description of the science content of the channel. \n",
    "\n",
    "\n",
    "As in Tutorial 2, this notebook thus assumes a mongod instance to be running and accessible through 27017. (The port can be changed through the mongo key of the ampel_config.yml file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%load_ext ampel_quick_import\n",
    "%qi DevAmpelContext AmpelLogger T2Processor T3Processor ChannelModel AlertProcessor TarAlertLoader ChannelModel AbsAlertFilter ProcessModel DefaultProcessController"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMPEL_CONF = \"../../ampel_config.yml\"\n",
    "ALERT_ARCHIVE = '../sample_data/ztfpub_200917_pruned.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The operation context is created based on a setup configuration file.\n",
    "# db_prefix sets the DB name to use\n",
    "ctx = DevAmpelContext.load(\n",
    "    config_file_path = AMPEL_CONF,\n",
    "    db_prefix = \"AmpelTutorial\",\n",
    "    purge_db = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-consistency",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.config.get( \"process.t0.SAMPLE_CHANNEL|T0|ztf_uw_public\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = ProcessModel(**ctx.config.get( \"process.t0.SAMPLE_CHANNEL|T0|ztf_uw_public\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DefaultProcessController??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = DefaultProcessController(config=ctx.config, processes=[pm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.run_process(pm=pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmt2 = ProcessModel(**ctx.config.get( \"process.t2.DefaultT2Process\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.run_process(pm=pmt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmt3 = ProcessModel(**ctx.config.get( \"process.t3.SAMPLE_CHANNEL|T3|summary_00\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d239631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.run_process(pm=pmt3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-partition",
   "metadata": {},
   "source": [
    "So far an input data stream has been filtered, and some sort of calculation has been done on the accepted sample. The next step for a full channel is usually some sort of _reaction_. These can vary between sending immediate alarms (e.g. through Slack or GCN), triggering follow-up observations or propagating information (e.g. for inspection in a frontent such as SkyPortal). \n",
    "\n",
    "Such reactions take place in the T3 tier. A simple `T3HelloWorld` unit is used, but the  `react` method can be configured to do most other things. Sample T3 units react with TNS, Slack, Dropbox, SkyPortal and GCN.\n",
    "\n",
    "Key steps of configuring the T3 procss comes through the `selection` directive, where we select tansients that produced the required target match, and the `execute` directive which regulates which T3 units are run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test base\n",
    "t3 = T3Processor(\n",
    "    context=ctx,\n",
    "    process_name = \"T3Processor_test\",\n",
    "    log_profile = \"default\", # debug\n",
    "    channel = \"demo_SN09if\",\n",
    "    directives = [ {\n",
    "        \"select\": {\n",
    "            \"unit\": \"T3FilteringStockSelector\",\n",
    "            \"config\": {\n",
    "                't2_filter':  {\n",
    "                    'unit': 'T2SNcosmoComp',\n",
    "                    'match': {'target_match': True}\n",
    "                }, \n",
    "            }\n",
    "        },\n",
    "        \"load\": {\n",
    "            \"unit\": \"T3SimpleDataLoader\",\n",
    "            \"config\": {\n",
    "                \"directives\": [\"TRANSIENT\", \"DATAPOINT\", \"COMPOUND\", \"T2RECORD\"],\n",
    "            }\n",
    "\n",
    "        },\n",
    "        \"run\": {\n",
    "            \"unit\": \"T3UnitRunner\",\n",
    "            \"config\": {\n",
    "                \"directives\": [\n",
    "                      {\n",
    "                            \"project\": {\n",
    "                                \"unit\": \"T3ChannelProjector\",\n",
    "                                \"config\": {\n",
    "                                    \"channel\": \"demo_SN09if\"\n",
    "                                }\n",
    "                            },\n",
    "                            \"execute\": [\n",
    "                                {\n",
    "                                    \"unit\": \"T3HelloWorld\",\n",
    "                                    \"config\": {\n",
    "                                        't2info_from' : ['T2SNcosmoComp', 'T2MultiMessMatch']\n",
    "                                    },\n",
    "                                },\n",
    "                            ]\n",
    "\n",
    "                      }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    } ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "t3.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-dating",
   "metadata": {},
   "source": [
    "### Match to (multi-messenger) coincidence region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-raising",
   "metadata": {},
   "source": [
    "The most common way to work with multi-messenger data is to match optical data with some confidence region provided by another detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "controller??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-gambling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-ministry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-norman",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-retrieval",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-invitation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-parcel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-artwork",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-things",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-realtor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-sheriff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
